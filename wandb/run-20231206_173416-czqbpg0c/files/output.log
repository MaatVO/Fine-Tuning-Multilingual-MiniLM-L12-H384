
  0%|         | 0/60 [00:00<?, ?it/s]You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.





 10%| | 6/60 [00:13<01:48,  2.02s/it]





 20%|▏| 12/60 [00:27<01:43,  2.16s/it




 28%|▎| 17/60 [00:40<01:47,  2.49s/it







 40%|▍| 24/60 [00:57<01:19,  2.21s/it





 50%|▌| 30/60 [01:11<01:00,  2.00s/it





 58%|▌| 35/60 [01:24<00:57,  2.28s/it






 70%|▋| 42/60 [01:41<00:40,  2.23s/it






 80%|▊| 48/60 [01:57<00:28,  2.38s/it






 90%|▉| 54/60 [02:13<00:14,  2.40s/it






100%|█| 60/60 [02:29<00:00,  2.47s/it

100%|█| 60/60 [02:31<00:00,  2.53s/it
{'train_runtime': 155.68, 'train_samples_per_second': 5.781, 'train_steps_per_second': 0.385, 'train_loss': 0.6828503290812175, 'epoch': 10.0}