
You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
C:\Users\matti\AppData\Local\Temp\ipykernel_3588\2963144971.py:18: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate
  metric[met] = load_metric(met)
{'eval_loss': 0.6245359778404236, 'eval_accuracy': 0.6463414634146342, 'eval_recall': 0.4166666666666667, 'eval_precision': 0.6521739130434783, 'eval_f1': 0.5084745762711865, 'eval_runtime': 17.0078, 'eval_samples_per_second': 4.821, 'eval_steps_per_second': 0.353, 'epoch': 1.0}
{'eval_loss': 0.6748529672622681, 'eval_accuracy': 0.6219512195121951, 'eval_recall': 0.8888888888888888, 'eval_precision': 0.5423728813559322, 'eval_f1': 0.6736842105263159, 'eval_runtime': 17.0166, 'eval_samples_per_second': 4.819, 'eval_steps_per_second': 0.353, 'epoch': 2.0}
{'eval_loss': 0.5825518369674683, 'eval_accuracy': 0.7317073170731707, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.7058823529411765, 'eval_f1': 0.6857142857142857, 'eval_runtime': 16.8048, 'eval_samples_per_second': 4.88, 'eval_steps_per_second': 0.357, 'epoch': 3.0}
{'eval_loss': 0.6550952196121216, 'eval_accuracy': 0.6829268292682927, 'eval_recall': 0.6111111111111112, 'eval_precision': 0.6470588235294118, 'eval_f1': 0.6285714285714287, 'eval_runtime': 16.7682, 'eval_samples_per_second': 4.89, 'eval_steps_per_second': 0.358, 'epoch': 4.0}
{'eval_loss': 0.6862753629684448, 'eval_accuracy': 0.6707317073170732, 'eval_recall': 0.7222222222222222, 'eval_precision': 0.6046511627906976, 'eval_f1': 0.6582278481012659, 'eval_runtime': 16.8961, 'eval_samples_per_second': 4.853, 'eval_steps_per_second': 0.355, 'epoch': 5.0}
{'loss': 0.5591, 'learning_rate': 1.6415770609318996e-05, 'epoch': 5.38}
{'eval_loss': 0.7061823010444641, 'eval_accuracy': 0.6463414634146342, 'eval_recall': 0.7777777777777778, 'eval_precision': 0.5714285714285714, 'eval_f1': 0.6588235294117646, 'eval_runtime': 16.9515, 'eval_samples_per_second': 4.837, 'eval_steps_per_second': 0.354, 'epoch': 6.0}
{'eval_loss': 0.7232234477996826, 'eval_accuracy': 0.6707317073170732, 'eval_recall': 0.6388888888888888, 'eval_precision': 0.6216216216216216, 'eval_f1': 0.6301369863013699, 'eval_runtime': 16.928, 'eval_samples_per_second': 4.844, 'eval_steps_per_second': 0.354, 'epoch': 7.0}
{'eval_loss': 0.721763551235199, 'eval_accuracy': 0.7317073170731707, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.75, 'eval_f1': 0.6562499999999999, 'eval_runtime': 16.8521, 'eval_samples_per_second': 4.866, 'eval_steps_per_second': 0.356, 'epoch': 8.0}
{'eval_loss': 0.8492879867553711, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.6944444444444444, 'eval_precision': 0.5952380952380952, 'eval_f1': 0.6410256410256411, 'eval_runtime': 17.0215, 'eval_samples_per_second': 4.817, 'eval_steps_per_second': 0.352, 'epoch': 9.0}
{'eval_loss': 0.9549925327301025, 'eval_accuracy': 0.6219512195121951, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.5581395348837209, 'eval_f1': 0.6075949367088608, 'eval_runtime': 16.9828, 'eval_samples_per_second': 4.828, 'eval_steps_per_second': 0.353, 'epoch': 10.0}
{'loss': 0.3612, 'learning_rate': 1.2831541218637992e-05, 'epoch': 10.75}
{'eval_loss': 0.951691210269928, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.5833333333333334, 'eval_precision': 0.6176470588235294, 'eval_f1': 0.6, 'eval_runtime': 16.8059, 'eval_samples_per_second': 4.879, 'eval_steps_per_second': 0.357, 'epoch': 11.0}
{'eval_loss': 1.084074854850769, 'eval_accuracy': 0.6341463414634146, 'eval_recall': 0.6944444444444444, 'eval_precision': 0.5681818181818182, 'eval_f1': 0.625, 'eval_runtime': 16.9378, 'eval_samples_per_second': 4.841, 'eval_steps_per_second': 0.354, 'epoch': 12.0}
{'eval_loss': 1.161428689956665, 'eval_accuracy': 0.6341463414634146, 'eval_recall': 0.75, 'eval_precision': 0.5625, 'eval_f1': 0.6428571428571429, 'eval_runtime': 17.0089, 'eval_samples_per_second': 4.821, 'eval_steps_per_second': 0.353, 'epoch': 13.0}
{'eval_loss': 1.114166259765625, 'eval_accuracy': 0.6463414634146342, 'eval_recall': 0.7222222222222222, 'eval_precision': 0.5777777777777777, 'eval_f1': 0.6419753086419753, 'eval_runtime': 16.9186, 'eval_samples_per_second': 4.847, 'eval_steps_per_second': 0.355, 'epoch': 14.0}
{'eval_loss': 1.1592769622802734, 'eval_accuracy': 0.6341463414634146, 'eval_recall': 0.7222222222222222, 'eval_precision': 0.5652173913043478, 'eval_f1': 0.6341463414634146, 'eval_runtime': 17.0834, 'eval_samples_per_second': 4.8, 'eval_steps_per_second': 0.351, 'epoch': 15.0}
{'eval_loss': 1.014045000076294, 'eval_accuracy': 0.6829268292682927, 'eval_recall': 0.6944444444444444, 'eval_precision': 0.625, 'eval_f1': 0.6578947368421053, 'eval_runtime': 20.3664, 'eval_samples_per_second': 4.026, 'eval_steps_per_second': 0.295, 'epoch': 16.0}
{'loss': 0.2323, 'learning_rate': 9.24731182795699e-06, 'epoch': 16.13}
{'eval_loss': 1.07355797290802, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.6111111111111112, 'eval_precision': 0.6111111111111112, 'eval_f1': 0.6111111111111112, 'eval_runtime': 20.4694, 'eval_samples_per_second': 4.006, 'eval_steps_per_second': 0.293, 'epoch': 17.0}
{'eval_loss': 1.1553186178207397, 'eval_accuracy': 0.6463414634146342, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.5853658536585366, 'eval_f1': 0.6233766233766234, 'eval_runtime': 17.0995, 'eval_samples_per_second': 4.795, 'eval_steps_per_second': 0.351, 'epoch': 18.0}
{'eval_loss': 1.1489641666412354, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.5555555555555556, 'eval_precision': 0.625, 'eval_f1': 0.5882352941176471, 'eval_runtime': 18.3585, 'eval_samples_per_second': 4.467, 'eval_steps_per_second': 0.327, 'epoch': 19.0}
{'eval_loss': 1.1682543754577637, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.6, 'eval_f1': 0.631578947368421, 'eval_runtime': 18.5583, 'eval_samples_per_second': 4.419, 'eval_steps_per_second': 0.323, 'epoch': 20.0}
{'eval_loss': 1.1947252750396729, 'eval_accuracy': 0.6463414634146342, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.5853658536585366, 'eval_f1': 0.6233766233766234, 'eval_runtime': 18.5008, 'eval_samples_per_second': 4.432, 'eval_steps_per_second': 0.324, 'epoch': 21.0}
{'loss': 0.1631, 'learning_rate': 5.663082437275986e-06, 'epoch': 21.51}
{'eval_loss': 1.267398715019226, 'eval_accuracy': 0.6341463414634146, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.5714285714285714, 'eval_f1': 0.6153846153846153, 'eval_runtime': 18.4385, 'eval_samples_per_second': 4.447, 'eval_steps_per_second': 0.325, 'epoch': 22.0}
{'eval_loss': 1.2994301319122314, 'eval_accuracy': 0.6219512195121951, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.5581395348837209, 'eval_f1': 0.6075949367088608, 'eval_runtime': 18.6062, 'eval_samples_per_second': 4.407, 'eval_steps_per_second': 0.322, 'epoch': 23.0}
{'eval_loss': 1.370114803314209, 'eval_accuracy': 0.6219512195121951, 'eval_recall': 0.7222222222222222, 'eval_precision': 0.5531914893617021, 'eval_f1': 0.6265060240963856, 'eval_runtime': 18.4476, 'eval_samples_per_second': 4.445, 'eval_steps_per_second': 0.325, 'epoch': 24.0}
{'eval_loss': 1.2410484552383423, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.6944444444444444, 'eval_precision': 0.5952380952380952, 'eval_f1': 0.6410256410256411, 'eval_runtime': 18.4984, 'eval_samples_per_second': 4.433, 'eval_steps_per_second': 0.324, 'epoch': 25.0}
{'eval_loss': 1.3331689834594727, 'eval_accuracy': 0.6341463414634146, 'eval_recall': 0.6111111111111112, 'eval_precision': 0.5789473684210527, 'eval_f1': 0.5945945945945946, 'eval_runtime': 18.3832, 'eval_samples_per_second': 4.461, 'eval_steps_per_second': 0.326, 'epoch': 26.0}
{'loss': 0.1279, 'learning_rate': 2.078853046594982e-06, 'epoch': 26.88}
{'eval_loss': 1.2516299486160278, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.6, 'eval_f1': 0.631578947368421, 'eval_runtime': 18.5001, 'eval_samples_per_second': 4.432, 'eval_steps_per_second': 0.324, 'epoch': 27.0}
{'eval_loss': 1.2635318040847778, 'eval_accuracy': 0.6585365853658537, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.6, 'eval_f1': 0.631578947368421, 'eval_runtime': 18.3498, 'eval_samples_per_second': 4.469, 'eval_steps_per_second': 0.327, 'epoch': 28.0}
{'eval_loss': 1.2904584407806396, 'eval_accuracy': 0.6463414634146342, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.5853658536585366, 'eval_f1': 0.6233766233766234, 'eval_runtime': 18.3985, 'eval_samples_per_second': 4.457, 'eval_steps_per_second': 0.326, 'epoch': 29.0}
{'eval_loss': 1.2934504747390747, 'eval_accuracy': 0.6463414634146342, 'eval_recall': 0.6666666666666666, 'eval_precision': 0.5853658536585366, 'eval_f1': 0.6233766233766234, 'eval_runtime': 18.4177, 'eval_samples_per_second': 4.452, 'eval_steps_per_second': 0.326, 'epoch': 30.0}
{'train_runtime': 27000.9337, 'train_samples_per_second': 1.64, 'train_steps_per_second': 0.103, 'train_loss': 0.27100956004153015, 'epoch': 30.0}
bert.embeddings.word_embeddings.weight: Requires Grad - True
bert.embeddings.position_embeddings.weight: Requires Grad - True
bert.embeddings.token_type_embeddings.weight: Requires Grad - True
bert.embeddings.LayerNorm.weight: Requires Grad - True
bert.embeddings.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.0.attention.self.query.weight: Requires Grad - False
bert.encoder.layer.0.attention.self.query.bias: Requires Grad - False
bert.encoder.layer.0.attention.self.key.weight: Requires Grad - False
bert.encoder.layer.0.attention.self.key.bias: Requires Grad - False
bert.encoder.layer.0.attention.self.value.weight: Requires Grad - False
bert.encoder.layer.0.attention.self.value.bias: Requires Grad - False
bert.encoder.layer.0.attention.output.dense.weight: Requires Grad - False
bert.encoder.layer.0.attention.output.dense.bias: Requires Grad - False
bert.encoder.layer.0.attention.output.LayerNorm.weight: Requires Grad - False
bert.encoder.layer.0.attention.output.LayerNorm.bias: Requires Grad - False
bert.encoder.layer.0.intermediate.dense.weight: Requires Grad - False
bert.encoder.layer.0.intermediate.dense.bias: Requires Grad - False
bert.encoder.layer.0.output.dense.weight: Requires Grad - False
bert.encoder.layer.0.output.dense.bias: Requires Grad - False
bert.encoder.layer.0.output.LayerNorm.weight: Requires Grad - False
bert.encoder.layer.0.output.LayerNorm.bias: Requires Grad - False
bert.encoder.layer.1.attention.self.query.weight: Requires Grad - False
bert.encoder.layer.1.attention.self.query.bias: Requires Grad - False
bert.encoder.layer.1.attention.self.key.weight: Requires Grad - False
bert.encoder.layer.1.attention.self.key.bias: Requires Grad - False
bert.encoder.layer.1.attention.self.value.weight: Requires Grad - False
bert.encoder.layer.1.attention.self.value.bias: Requires Grad - False
bert.encoder.layer.1.attention.output.dense.weight: Requires Grad - False
bert.encoder.layer.1.attention.output.dense.bias: Requires Grad - False
bert.encoder.layer.1.attention.output.LayerNorm.weight: Requires Grad - False
bert.encoder.layer.1.attention.output.LayerNorm.bias: Requires Grad - False
bert.encoder.layer.1.intermediate.dense.weight: Requires Grad - False
bert.encoder.layer.1.intermediate.dense.bias: Requires Grad - False
bert.encoder.layer.1.output.dense.weight: Requires Grad - False
bert.encoder.layer.1.output.dense.bias: Requires Grad - False
bert.encoder.layer.1.output.LayerNorm.weight: Requires Grad - False
bert.encoder.layer.1.output.LayerNorm.bias: Requires Grad - False
bert.encoder.layer.2.attention.self.query.weight: Requires Grad - False
bert.encoder.layer.2.attention.self.query.bias: Requires Grad - False
bert.encoder.layer.2.attention.self.key.weight: Requires Grad - False
bert.encoder.layer.2.attention.self.key.bias: Requires Grad - False
bert.encoder.layer.2.attention.self.value.weight: Requires Grad - False
bert.encoder.layer.2.attention.self.value.bias: Requires Grad - False
bert.encoder.layer.2.attention.output.dense.weight: Requires Grad - False
bert.encoder.layer.2.attention.output.dense.bias: Requires Grad - False
bert.encoder.layer.2.attention.output.LayerNorm.weight: Requires Grad - False
bert.encoder.layer.2.attention.output.LayerNorm.bias: Requires Grad - False
bert.encoder.layer.2.intermediate.dense.weight: Requires Grad - False
bert.encoder.layer.2.intermediate.dense.bias: Requires Grad - False
bert.encoder.layer.2.output.dense.weight: Requires Grad - False
bert.encoder.layer.2.output.dense.bias: Requires Grad - False
bert.encoder.layer.2.output.LayerNorm.weight: Requires Grad - False
bert.encoder.layer.2.output.LayerNorm.bias: Requires Grad - False
bert.encoder.layer.3.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.3.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.3.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.3.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.3.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.3.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.3.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.3.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.3.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.3.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.3.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.3.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.3.output.dense.weight: Requires Grad - True
bert.encoder.layer.3.output.dense.bias: Requires Grad - True
bert.encoder.layer.3.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.3.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.4.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.4.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.4.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.4.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.4.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.4.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.4.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.4.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.4.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.4.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.4.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.4.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.4.output.dense.weight: Requires Grad - True
bert.encoder.layer.4.output.dense.bias: Requires Grad - True
bert.encoder.layer.4.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.4.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.5.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.5.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.5.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.5.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.5.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.5.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.5.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.5.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.5.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.5.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.5.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.5.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.5.output.dense.weight: Requires Grad - True
bert.encoder.layer.5.output.dense.bias: Requires Grad - True
bert.encoder.layer.5.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.5.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.6.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.6.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.6.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.6.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.6.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.6.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.6.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.6.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.6.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.6.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.6.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.6.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.6.output.dense.weight: Requires Grad - True
bert.encoder.layer.6.output.dense.bias: Requires Grad - True
bert.encoder.layer.6.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.6.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.7.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.7.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.7.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.7.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.7.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.7.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.7.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.7.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.7.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.7.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.7.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.7.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.7.output.dense.weight: Requires Grad - True
bert.encoder.layer.7.output.dense.bias: Requires Grad - True
bert.encoder.layer.7.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.7.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.8.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.8.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.8.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.8.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.8.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.8.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.8.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.8.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.8.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.8.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.8.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.8.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.8.output.dense.weight: Requires Grad - True
bert.encoder.layer.8.output.dense.bias: Requires Grad - True
bert.encoder.layer.8.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.8.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.9.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.9.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.9.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.9.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.9.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.9.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.9.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.9.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.9.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.9.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.9.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.9.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.9.output.dense.weight: Requires Grad - True
bert.encoder.layer.9.output.dense.bias: Requires Grad - True
bert.encoder.layer.9.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.9.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.10.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.10.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.10.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.10.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.10.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.10.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.10.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.10.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.10.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.10.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.10.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.10.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.10.output.dense.weight: Requires Grad - True
bert.encoder.layer.10.output.dense.bias: Requires Grad - True
bert.encoder.layer.10.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.10.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.11.attention.self.query.weight: Requires Grad - True
bert.encoder.layer.11.attention.self.query.bias: Requires Grad - True
bert.encoder.layer.11.attention.self.key.weight: Requires Grad - True
bert.encoder.layer.11.attention.self.key.bias: Requires Grad - True
bert.encoder.layer.11.attention.self.value.weight: Requires Grad - True
bert.encoder.layer.11.attention.self.value.bias: Requires Grad - True
bert.encoder.layer.11.attention.output.dense.weight: Requires Grad - True
bert.encoder.layer.11.attention.output.dense.bias: Requires Grad - True
bert.encoder.layer.11.attention.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.11.attention.output.LayerNorm.bias: Requires Grad - True
bert.encoder.layer.11.intermediate.dense.weight: Requires Grad - True
bert.encoder.layer.11.intermediate.dense.bias: Requires Grad - True
bert.encoder.layer.11.output.dense.weight: Requires Grad - True
bert.encoder.layer.11.output.dense.bias: Requires Grad - True
bert.encoder.layer.11.output.LayerNorm.weight: Requires Grad - True
bert.encoder.layer.11.output.LayerNorm.bias: Requires Grad - True
bert.pooler.dense.weight: Requires Grad - True
bert.pooler.dense.bias: Requires Grad - True
classifier.weight: Requires Grad - True
classifier.bias: Requires Grad - True
